\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsfonts}

\title{Distributed Graph Processing for Machine Learning:\\
The Case for Condor and Spot Instances}
\author{Jing Fan~~~~~Ce Zhang}
\date{}

\begin{document}
\maketitle

\begin{abstract}
We study distributed graph processing for machine learning
applications in an environment
in which the failure of workers is guaranteed to happen
frequently. Notable examples of such environments can be found
both in the classic grid computing, e.g., Condor, and the emerging
cloud computing, e.g., {\em spot instances} on Amazon EC2.
Different from the common practice that running
machine learning algorithms with a dedicated cluster,
it is still an open research question that how (and whether
it is possible) to run machine learning algorithms in
this environment.

This report documents our {\em preliminary} effort towards 
answering this question by building a prototype system. 
Ideally, we have two goals: (1) {\em expressiveness}:
this prototype system should allow the user to specify
a machine learning system as easy as existing frameworks
designed for dedicated clusters; and (2) {\em efficiency}:
the machine learning system specified by the prototype system
should be able to run in environments such as Condor efficiently.
We report our design of this prototype system that extends
the programming model of a popular graph-processing engine,
namely GraphLab. Given a user program written in our language
extension, we describe the execution model. We validate
our prototype system with an emergingly popular machine
learning application, namely deep neural network, on {\em both}
Condor and Amazon EC2. We find that our prototype system is
able to achieve more than 12TFLOPS on Condor with more than
2.6K cores harvest from the national Open Science Grid (OSG).

\end{abstract}

\section{Introduction}

Machine learning has been one emerging area that
attracts interests from the community of system 
research, especially research of 
distributed systems~\cite{Li:2014:OSDI,GraphLab:OSDI}. 
Notable example including GraphLab~\cite{GraphLab:OSDI},
Spark~\cite{Spark}, Google's DistBelief~\cite{Google}, and 
Yahoo's Parameter Server~\cite{Yahoo,Li:2014:OSDI}. 
In this work, we focus on the same goal, that is 
to build a framework that supports executing machine 
learning applications in an distributed environment.

It has been a common practice for distributed machine
learning systems to be run on dedicated clusters.
For example, both Spark and GraphLab has been 
reported to be able to execute machine learning algorithms
on hundreds of machines; DistBelief is able to 
train deep neural network on 6000 machines; and 
Parameter Server is able to scale to 1000 machines.
Our key observation is that existing frameworks~\cite{Li:2014:OSDI,
GraphLab:OSDI,Spark,Google,Yahoo} implicitly
make {\em at least one} of the following two assumption
about the distributed environment and workload:

\begin{enumerate}
\item The coordinators know {\em a priori} 
the set of worker nodes, including their configuration,
number of worker nodes, and the network topology between
these workers. These information are necessary for most
existing systems to schedule their workload before
execution. For example, Yahoo's Parameter Server
uses consistent hashing~\cite{Li:2014:OSDI} to allocate
resources and workers, and use chain replication to
deal worker failures. GraphLab~\cite{GraphLab:OSDI} also
uses similar approaches. 
\item The graph to be processed consists of nodes that are 
executed with the same level of consistency. For example,
in GraphLab, the execution engine can choose from three
different consistency levels, and all the nodes in the same
graph will follow the same level.  
\end{enumerate}

These assumptions are often true in the environment that
these systems are designed for, in which the cluster is
maintained in a centralized way or leased with cloud-based
services (e.g., EC2). However, this assumption
does not always hold for a popular environment that
often be called {\em high throughput computation} (HTC) 
environment. One notable example is Condor, which,
when ran on the national open science grid, can easily
harvest hundreds of thousands of machine hours per day.
Another example is the spot instance on Amazon EC2, which 
relies on a bidding-based model that could provide much
cheaper solution than traditional cloud-based instances.
These HTC environments have the characteristics that are
different to the above two assumptions when applied to 
machine learning.

\begin{enumerate}
\item The coordinators does not know the set of workers
{\em a priori}. For example, in Condor, the coordinator
does not know how many workers will be assigned to it, and
what type of machines will be assigned to it. Also, the
workers are not guaranteed to be able to communicate with each
other. Similar scenario applies to spot instances
of EC2, in which the number of workers assigned to the
coordinator depends on the bidding price and other bidder, while
the configuration of machines are known to the coordinator.
\item Machine learning workload often contains heterogeneous
consistency requirement. For example, for some data
in machine learning workload, full consistency is not required,
while for other data, one might need higher-level of consistency.
This observation has also been made in a subset of
existing systems, e.g., Parameter Server~\cite{Li:2014:OSDI}.
\end{enumerate}

We study how to build a GraphLab-like system with these two
observations, and study their implications on system design.
We first propose a language extension of GraphLab for the
user to specify a machine learning algorithm, and use
Deep Neural Network (DNN) as an use case. We then study
the design decisions we made for both Condor and spot
instances of Amazon EC2. We validate our prototype system
on standard benchmark data sets.

\section{System Design}

We describe the design decisions and how they relate to
the two observations we made on Condor and spot
instances of Amazon EC2. We first describe in more details
about these environment, and present the language extension
and execution model.

\begin{figure}[t]
\centering
\includegraphics[width=0.9\textwidth]{figures/env-crop}
\caption{An illustration of (a) dedicated cluster and (b) Condor/Spot-instances. (b) illustrates three states in different time where the worker machines keeps come in and fail.}
\label{fig:env}
\end{figure}

\subsection{Condor and Spot Instance of EC2}

Figure~\ref{fig:env} illustrates the difference between
a dedicated cluster, Condor instances, and EC2 instances.
We describe their difference as follows.

\paragraph*{Dedicated Cluster} The dedicated cluster
that existing work assumes usually contains two components:
(1) a set of master machines; and (2) a set of worker machines.
In some frameworks, master machines and worker machines
could overlap. A dedicated cluster starts from a given
set of machines, and when the job starts, this number is
known to the system. Therefore, one could use techniques
like consistent hashing to allocate resources. Faults
are assumed for both worker and master, and therefore,
one could use techniques like chain replication. However,
the failure rate is usually low compared with the two scenario
that we are going to discuss later.

\paragraph*{Condor} Figure~\ref{fig:env}(b) illustrates
the case for Condor. Similar to dedicated cluster, there
are workers and masters. The cluster starts with only
master machines and zero workers. During execution,
workers are added to the pool periodically, but also
fail periodically. According to the statistics we get
from OSG, the same worker usually has a life span around
45 minutes, which means, after 45 minutes a worker will
exit. Usually, workers cannot communicate with each other
because they are behind the firewall of different organizations
cross the country.

\paragraph*{EC2 Spot Instances} The spot instances
of EC2 has similar structure with Condor. New instances
will be added into the pool when the bidding price is
higher than the market price; and instances will be removed
from the pool when the bidding price is lower than
the market price. Because the market price is unknown and
keep changing dynamically, there is no way for the master
to know beforehand the number of worker machines.

\subsection{Language Extension}

\subsection{Execution Model}


\paragraph*{Deciding the Chunk Size}

One key parameter that we need to decide is the
chunk size, that is the number of nodes we can
put in a single job. We apply standard queueing
theory to estimate this parameter. 

Let $N$ be the total number of vertex, and $t_{exec}$
be the time that a single vertex needs to
finish execution. Let $t_s$ and $t_e$ be the time
that Condor needs to start and end a job. Let
$t_c$ be the time that each vertex require to copy
to the worker.
Let $T$ be the time that a Condor worker can execute
before getting killed. Let $n$ be the number of 
vertex we put in a single Condor job.
%
We have that there are $N/n$ Condor jobs, each of which
takes $nt_{exec}$ time to execute. 

\subparagraph*{Infinite Bandwidth with Deterministic Failure}

We first assume that the master has infinite bandwidth,
and therefore, no matter how many jobs we have, they
do not interfere with each other. In this case, let
$M$ be the number of Condor machines we get, the
total execution time is
\[
TotalTime(n) = \frac{N}{n} \mathbb{I}_{T>n(t_c+t_{exec})} \left[ t_s + nt_c + nt_{exec}  + t_e \right]
\]
If we want to maximize
\[
\frac{Nt_{exec}}{TotalTime(n)}
\]
we just need to set
\[
T=n(t_c+t_{exec}).
\]

\subparagraph*{Infinite Bandwidth with Stochastic Failure}

Our previous analysis assumes that Condor jobs fail
deterministically after time $T$. A more tight and realistic
analysis is to assume this parameter is stochastic. For example,
let $T\sim\mathcal{N}(\mu, \sigma^2)$ be a Gaussian random variable.
Now $TotalTime(n)$ becomes a random variable.
Instead of analyzing this random variable as a whole, let's
look at a single job.
\[
TimeOfAJob(n) = \mathbb{I}_{T>n(t_c+t_{exec})} \left[ t_s + nt_c + nt_{exec}  + t_e \right]
\]
The expectation of this random variable is
\[
\mathbb{E}\left[TimeOfAJob(n)\right] = \Pr[T>n(t_c+t_{exec})] \left[ t_s + nt_c + nt_{exec}  + t_e \right]
\]
Let $\Phi_{\mu,\sigma}$ be the quantile function
of the Gaussian distribution, we have
\[
\mathbb{E}\left[TimeOfAJob(n)\right] = \Phi(n(t_c+t_{exec})) \left[ t_s + nt_c + nt_{exec}  + t_e \right]
\]
Trivially, the expectation of $TotalTime(n)$ becomes
\[
\mathbb{E}\left[TotalTime(n)\right] = \frac{N}{n} \Phi(n(t_c+t_{exec})) \left[ t_s + nt_c + nt_{exec}  + t_e \right]
\]
The best chunk size should be the one that minimizes this 
expectation. However, it is well-known that the quantile
function of Gaussian cannot be expressed in closed form in 
terms of elementary functions; therefore, one can use
standard numerical methods to search for (local) minimal
of this function.


\section{Performance Study}

We describe 




\bibliographystyle{abbrv}
\bibliography{report}

\end{document}


















